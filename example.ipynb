{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09016393442622943"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the rare disease example, what is the probability of having the disease given that, \n",
    "# 1. you have tested positive at first test \n",
    "# 2. you have tested positive at first and second test \n",
    "# 3. you have tested positive at first test and negative at second test.\n",
    "# x is the average probability of having the disease; y is the reliability of the test.\n",
    "# n is the no. of positive test; m is the no. of negative test\n",
    "\n",
    "# 1, 2, 3\n",
    "def probability_of_disease(x, y, n, m):\n",
    "    return 1/(1+(((1-y)**n)*(y**m))*(1-x)/(x*(y**n)*(1-y)**m))\n",
    "  \n",
    "probability_of_disease(0.001, 0.99,2,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# check no. of cores\n",
    "import multiprocessing as mp\n",
    "print(mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ler.utils import get_param_from_json\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "from ler.rates import LeR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_to_luminosity_distance interpolator will be loaded from ./interpolator_pickle/z_to_luminosity_distance/z_to_luminosity_distance_0.pickle\n",
      "differential_comoving_volume interpolator will be loaded from ./interpolator_pickle/differential_comoving_volume/differential_comoving_volume_0.pickle\n",
      "merger_rate_density_bbh_popI_II_oguri2018 interpolator will be loaded from ./interpolator_pickle/merger_rate_density_bbh_popI_II_oguri2018/merger_rate_density_bbh_popI_II_oguri2018_1.pickle\n",
      "z_to_Dc interpolator will be loaded from ./interpolator_pickle/z_to_Dc/z_to_Dc_0.pickle\n",
      "Dc_to_z interpolator will be loaded from ./interpolator_pickle/Dc_to_z/Dc_to_z_0.pickle\n",
      "angular_diameter_distance interpolator will be loaded from ./interpolator_pickle/angular_diameter_distance/angular_diameter_distance_0.pickle\n",
      "differential_comoving_volume interpolator will be loaded from ./interpolator_pickle/differential_comoving_volume/differential_comoving_volume_1.pickle\n",
      "velocity_dispersion_gengamma interpolator will be loaded from ./interpolator_pickle/velocity_dispersion_gengamma/velocity_dispersion_gengamma_0.pickle\n",
      "Dl_to_z interpolator will be loaded from ./interpolator_pickle/Dl_to_z/Dl_to_z_0.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 13:12:15.335551: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-29 13:12:15.425962: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-29 13:12:16.031336: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-29 13:12:16.035821: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-29 13:12:17.300902: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npool:  4\n",
      "snr type:  interpolation\n",
      "waveform approximant:  IMRPhenomD\n",
      "sampling frequency:  2048\n",
      "minimum frequency (fmin):  20.0\n",
      "mtot=mass1+mass2\n",
      "min(mtot):  2.0\n",
      "max(mtot) (with the given fmin=20.0): 184.98599853446768\n",
      "detectors:  None\n",
      "min(ratio):  0.1\n",
      "max(ratio):  1.0\n",
      "mtot resolution:  500\n",
      "ratio resolution:  50\n",
      "interpolator directory:  ./interpolator_pickle\n",
      "Interpolator will be loaded for L1 detector from ./interpolator_pickle/L1/partialSNR_dict_0.pickle\n",
      "Interpolator will be loaded for H1 detector from ./interpolator_pickle/H1/partialSNR_dict_0.pickle\n",
      "Interpolator will be loaded for V1 detector from ./interpolator_pickle/V1/partialSNR_dict_1.pickle\n",
      "\n",
      " LeR set up params:\n",
      "npool =  4\n",
      "z_min =  0.0\n",
      "z_max =  10.0\n",
      "event_type =  BBH\n",
      "size =  100000\n",
      "batch_size =  50000\n",
      "cosmology =  LambdaCDM(H0=70.0 km / (Mpc s), Om0=0.3, Ode0=0.7, Tcmb0=0.0 K, Neff=3.04, m_nu=None, Ob0=None)\n",
      "snr_finder =  <bound method GWSNR.snr of <gwsnr.gwsnr.GWSNR object at 0x7f2c109d4e50>>\n",
      "json_file_names =  {'ler_params': 'ler_params.json', 'unlensed_param': 'unlensed_param.json', 'unlensed_param_detectable': 'unlensed_param_detectable.json', 'lensed_param': 'lensed_param.json', 'lensed_param_detectable': 'lensed_param_detectable.json'}\n",
      "interpolator_directory =  ./interpolator_pickle\n",
      "ler_directory =  ./ler_data\n",
      "\n",
      " LeR also takes CBCSourceParameterDistribution params as kwargs, as follows:\n",
      "source_priors= {'merger_rate_density': 'merger_rate_density_bbh_popI_II_oguri2018', 'source_frame_masses': 'binary_masses_BBH_popI_II_powerlaw_gaussian', 'zs': 'sample_source_redshift', 'geocent_time': 'sampler_uniform', 'ra': 'sampler_uniform', 'dec': 'sampler_cosine', 'phase': 'sampler_uniform', 'psi': 'sampler_uniform', 'theta_jn': 'sampler_sine'}\n",
      "source_priors_params= {'merger_rate_density': {'R0': 2.39e-08, 'b2': 1.6, 'b3': 2.1, 'b4': 30.0}, 'source_frame_masses': {'mminbh': 4.59, 'mmaxbh': 86.22, 'alpha': 2.63, 'mu_g': 33.07, 'sigma_g': 5.69, 'lambda_peak': 0.1, 'delta_m': 4.82, 'beta': 1.26}, 'zs': None, 'geocent_time': {'min_': 1238166018, 'max_': 1269702018}, 'ra': {'min_': 0.0, 'max_': 6.283185307179586}, 'dec': None, 'phase': {'min_': 0.0, 'max_': 6.283185307179586}, 'psi': {'min_': 0.0, 'max_': 3.141592653589793}, 'theta_jn': None}\n",
      "spin_zero= True\n",
      "spin_precession= False\n",
      "create_new_interpolator= False\n",
      "\n",
      " LeR also takes LensGalaxyParameterDistribution params as kwargs, as follows:\n",
      "lens_type =  epl_galaxy\n",
      "lens_functions =  {'strong_lensing_condition': 'rjs_with_cross_section_SIS', 'optical_depth': 'optical_depth_SIS_haris', 'param_sampler_type': 'sample_all_routine'}\n",
      "lens_priors =  {'source_redshift_sl': 'strongly_lensed_source_redshifts', 'lens_redshift': 'lens_redshift_SDSS_catalogue', 'velocity_dispersion': 'velocity_dispersion_gengamma', 'axis_ratio': 'axis_ratio_rayleigh', 'axis_rotation_angle': 'axis_rotation_angle_uniform', 'shear': 'shear_norm', 'mass_density_spectral_index': 'mass_density_spectral_index_normal', 'source_parameters': 'sample_gw_parameters'}\n",
      "lens_priors_params =  {'source_redshift_sl': None, 'lens_redshift': None, 'velocity_dispersion': {'a': 0.8689138576779026, 'c': 2.67}, 'axis_ratio': {'q_min': 0.2, 'q_max': 1.0}, 'axis_rotation_angle': {'phi_min': 0.0, 'phi_max': 6.283185307179586}, 'shear': {'scale': 0.05}, 'mass_density_spectral_index': {'mean': 2.0, 'std': 0.2}, 'source_parameters': None}\n",
      "\n",
      " Image properties:\n",
      "n_min_images =  2\n",
      "n_max_images =  4\n",
      "geocent_time_min =  1126259462.4\n",
      "geocent_time_max =  1756979462.4\n",
      "lens_model_list =  ['EPL_NUMBA', 'SHEAR']\n",
      "\n",
      " LeR also takes gwsnr.GWSNR params as kwargs, as follows:\n",
      "mtot_min =  2.0\n",
      "mtot_max =  184.98599853446768\n",
      "ratio_min =  0.1\n",
      "ratio_max =  1.0\n",
      "mtot_resolution =  500\n",
      "ratio_resolution =  50\n",
      "sampling_frequency =  2048\n",
      "waveform_approximant =  IMRPhenomD\n",
      "minimum_frequency =  20.0\n",
      "snr_type =  interpolation\n",
      "psds =  [PowerSpectralDensity(psd_file='None', asd_file='/home/lisali/anaconda3/envs/test/lib/python3.10/site-packages/bilby/gw/detector/noise_curves/aLIGO_O4_high_asd.txt'), PowerSpectralDensity(psd_file='None', asd_file='/home/lisali/anaconda3/envs/test/lib/python3.10/site-packages/bilby/gw/detector/noise_curves/aLIGO_O4_high_asd.txt'), PowerSpectralDensity(psd_file='/home/lisali/anaconda3/envs/test/lib/python3.10/site-packages/bilby/gw/detector/noise_curves/AdV_psd.txt', asd_file='None')]\n",
      "ifos =  ['L1', 'H1', 'V1']\n",
      "interpolator_dir =  ./interpolator_pickle\n",
      "create_new_interpolator =  False\n",
      "gwsnr_verbose =  True\n",
      "multiprocessing_verbose =  True\n",
      "mtot_cut =  True\n",
      "\n",
      " For reference, the chosen source parameters are listed below:\n",
      "merger_rate_density =  merger_rate_density_bbh_popI_II_oguri2018\n",
      "merger_rate_density_params =  {'R0': 2.39e-08, 'b2': 1.6, 'b3': 2.1, 'b4': 30.0}\n",
      "source_frame_masses =  binary_masses_BBH_popI_II_powerlaw_gaussian\n",
      "source_frame_masses_params =  {'mminbh': 4.59, 'mmaxbh': 86.22, 'alpha': 2.63, 'mu_g': 33.07, 'sigma_g': 5.69, 'lambda_peak': 0.1, 'delta_m': 4.82, 'beta': 1.26}\n",
      "geocent_time =  sampler_uniform\n",
      "geocent_time_params =  {'min_': 1238166018, 'max_': 1269702018}\n",
      "ra =  sampler_uniform\n",
      "ra_params =  {'min_': 0.0, 'max_': 6.283185307179586}\n",
      "dec =  sampler_cosine\n",
      "dec_params =  None\n",
      "phase =  sampler_uniform\n",
      "phase_params =  {'min_': 0.0, 'max_': 6.283185307179586}\n",
      "psi =  sampler_uniform\n",
      "psi_params =  {'min_': 0.0, 'max_': 3.141592653589793}\n",
      "theta_jn =  sampler_sine\n",
      "theta_jn_params =  None\n",
      "\n",
      " For reference, the chosen lens related parameters and functions are listed below:\n",
      "lens_redshift =  lens_redshift_SDSS_catalogue\n",
      "lens_redshift_params =  None\n",
      "velocity_dispersion =  velocity_dispersion_gengamma\n",
      "velocity_dispersion_params =  {'a': 0.8689138576779026, 'c': 2.67}\n",
      "axis_ratio =  axis_ratio_rayleigh\n",
      "axis_ratio_params =  {'q_min': 0.2, 'q_max': 1.0}\n",
      "axis_rotation_angle =  axis_rotation_angle_uniform\n",
      "axis_rotation_angle_params =  {'phi_min': 0.0, 'phi_max': 6.283185307179586}\n",
      "shear =  shear_norm\n",
      "shear_params =  {'scale': 0.05}\n",
      "mass_density_spectral_index =  mass_density_spectral_index_normal\n",
      "mass_density_spectral_index_params =  {'mean': 2.0, 'std': 0.2}\n",
      "Lens functions:\n",
      "strong_lensing_condition =  rjs_with_cross_section_SIS\n",
      "optical_depth =  optical_depth_SIS_haris\n"
     ]
    }
   ],
   "source": [
    "# initialize LeR\n",
    "ler = LeR(\n",
    "    # SNR related\n",
    "    sampling_frequency =  2048,\n",
    "    waveform_approximant =  'IMRPhenomD',\n",
    "    minimum_frequency =  20.0,\n",
    "    snr_type =  'interpolation',\n",
    "    ifos =  ['L1','H1','V1'],\n",
    "    # GW related\n",
    "    source_priors= {\n",
    "        'merger_rate_density': 'merger_rate_density_bbh_popI_II_oguri2018', \n",
    "        'source_frame_masses': 'binary_masses_BBH_popI_II_powerlaw_gaussian', \n",
    "        'zs': 'sample_source_redshift', \n",
    "        'geocent_time': 'sampler_uniform', \n",
    "        'ra': 'sampler_uniform', \n",
    "        'dec': 'sampler_cosine', \n",
    "        'phase': 'sampler_uniform', \n",
    "        'psi': 'sampler_uniform', \n",
    "        'theta_jn': 'sampler_sine'\n",
    "        },      \n",
    "    source_priors_params= {\n",
    "        'merger_rate_density': {'R0': 2.39e-08, 'b2': 1.6, 'b3': 2.1, 'b4': 30.}, \n",
    "        'source_frame_masses': {'mminbh': 4.59, 'mmaxbh': 86.22, 'alpha': 2.63, 'mu_g': 33.07, 'sigma_g': 5.69, 'lambda_peak': 0.10, 'delta_m': 4.82, 'beta': 1.26}, \n",
    "        'zs': None, \n",
    "        'geocent_time': {'min_': 1238166018, 'max_': 1269702018}, \n",
    "        'ra': {'min_': 0.0, 'max_': 6.283185307179586}, \n",
    "        'dec': None, \n",
    "        'phase': {'min_': 0.0, 'max_': 6.283185307179586}, \n",
    "        'psi': {'min_': 0.0, 'max_': 3.141592653589793}, \n",
    "        'theta_jn': None\n",
    "        },\n",
    "    spin_zero= True,\n",
    "    spin_precession= False,\n",
    "    # lens related\n",
    "    lens_type =  'epl_galaxy',\n",
    "    lens_functions =  {\n",
    "        'strong_lensing_condition': 'rjs_with_cross_section_SIS', \n",
    "        'optical_depth': 'optical_depth_SIS_haris', \n",
    "        'param_sampler_type': 'sample_all_routine',\n",
    "        },\n",
    "    lens_priors =  {\n",
    "        'source_redshift_sl': 'strongly_lensed_source_redshifts', \n",
    "        'lens_redshift': 'lens_redshift_SDSS_catalogue', \n",
    "        'velocity_dispersion': 'velocity_dispersion_gengamma', \n",
    "        'axis_ratio': 'axis_ratio_rayleigh', \n",
    "        'axis_rotation_angle': 'axis_rotation_angle_uniform', \n",
    "        'shear': 'shear_norm', \n",
    "        'mass_density_spectral_index': 'mass_density_spectral_index_normal', \n",
    "        'source_parameters': 'sample_gw_parameters',\n",
    "        },\n",
    "    lens_priors_params =  {\n",
    "        'source_redshift_sl': None, \n",
    "        'lens_redshift': None, \n",
    "        'velocity_dispersion': {'a':2.32 / 2.67, 'c':2.67}, \n",
    "        'axis_ratio': {'q_min': 0.2, 'q_max': 1.0}, \n",
    "        'axis_rotation_angle': {'phi_min': 0.0, 'phi_max': 2*np.pi}, \n",
    "        'shear': {'scale': 0.05}, \n",
    "        'mass_density_spectral_index': {'mean': 2.0, 'std': 0.2}, 'source_parameters': None\n",
    "    },\n",
    "    # image related\n",
    "    n_min_images = 2,\n",
    "    n_max_images = 4,\n",
    "    lens_model_list =  ['EPL_NUMBA', 'SHEAR'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unlensed params will be store in ./ler_data/unlensed_cbc_bbh.json\n",
      "chosen batch size = 50000 with total size = 100000\n",
      "There will be 2 batche(s)\n",
      "Batch no. 1\n",
      "sampling gw source params...\n",
      "calculating snrs...\n",
      "Batch no. 2\n",
      "sampling gw source params...\n",
      "calculating snrs...\n",
      "saving all unlensed_params in ./ler_data/unlensed_cbc_bbh.json...\n",
      "getting unlensed_params from json file ./ler_data/unlensed_cbc_bbh.json...\n",
      "given detectability_condition == 'step_function'\n",
      "total unlensed rate (yr^-1) (with step function): 1018.665302268693\n",
      "number of simulated unlensed detectable events: 984\n",
      "number of all simulated unlensed events: 100000\n",
      "storing detectable unlensed params in ./ler_data/unlensed_param_detectable.json\n",
      "lensed params will be store in ./ler_data/lensed_cbc_bbh.json\n",
      "chosen batch size = 50000 with total size = 100000\n",
      "There will be 2 batche(s)\n",
      "Batch no. 1\n",
      "sampling lensed params...\n",
      "solving lens equations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 50000/50000 [00:51<00:00, 971.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating snrs...\n",
      "Batch no. 2\n",
      "sampling lensed params...\n",
      "solving lens equations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 50000/50000 [01:01<00:00, 815.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid sample found. Resampling 2 lensed events...\n",
      "solving lens equations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating snrs...\n",
      "saving all lensed_params in ./ler_data/lensed_cbc_bbh.json...\n",
      "getting lensed_params from json file ./ler_data/lensed_cbc_bbh.json...\n",
      "given detectability_condition == 'step_function'\n",
      "total lensed rate (yr^-1) (with step function): 0.7429248944361975\n",
      "number of simulated lensed detectable events: 735\n",
      "number of simulated all lensed events: 100000\n",
      "storing detectable lensed params in ./ler_data/lensed_param_detectable.json\n",
      "unlensed_rate: 1018.665302268693\n",
      "lensed_rate: 0.7429248944361975\n",
      "ratio: 1371.1551596904742\n"
     ]
    }
   ],
   "source": [
    "# ler.batch_size = 100000 # for faster computation\n",
    "unlensed_param = ler.unlensed_cbc_statistics(size=100000, resume=False, save_batch=False,output_jsonfile='unlensed_cbc_bbh.json')\n",
    "\n",
    "_, unlensed_param_detectable = ler.unlensed_rate();\n",
    "\n",
    "# ler.batch_size = 50000\n",
    "lensed_param = ler.lensed_cbc_statistics(size=100000, resume=False, save_batch=False, output_jsonfile='lensed_cbc_bbh.json')\n",
    "\n",
    "_, lensed_param_detectable = ler.lensed_rate();\n",
    "\n",
    "ler.rate_ratio();\n",
    "# rate_ratio, unlensed_param_detectable, lensed_param_detectable = ler.rate_comparision_with_rate_calculation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.8348104  10.11220265 11.1424184   5.87834215]\n",
      " [12.7996451  10.42896172  7.9862931   0.        ]\n",
      " [ 2.38098694 10.87793207 10.21947747  5.59940677]\n",
      " ...\n",
      " [13.18900042  7.43813576 13.18544792  0.        ]\n",
      " [ 3.77616436 11.94355908 10.76819151  2.65123419]\n",
      " [ 8.00616781  9.95963045  0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "lensed_param_detectable = get_param_from_json('./ler_data/lensed_param_detectable.json')\n",
    "snr = lensed_param_detectable['optimal_snr_net']\n",
    "print(snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7034013605442176\n",
      "0.2054421768707483\n",
      "0.09115646258503401\n"
     ]
    }
   ],
   "source": [
    "# ratio of double, triple and quadruple images\n",
    "idx1 = abs(lensed_param_detectable['optimal_snr_net'])>8\n",
    "idx2 = np.sum(idx1, axis=1)\n",
    "ratio_double = np.sum(idx2==2)/len(idx2)\n",
    "ratio_triple = np.sum(idx2==3)/len(idx2)\n",
    "ratio_quadruple = np.sum(idx2==4)/len(idx2)\n",
    "print(ratio_double)\n",
    "print(ratio_triple)\n",
    "print(ratio_quadruple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.00000000e+00 0.00000000e+00 6.19877031e+05 6.64157561e+05\n",
      "  1.14358832e+06]\n",
      " [2.00000000e+00 0.00000000e+00 1.10552260e+06 4.64156569e+06\n",
      "  0.00000000e+00]\n",
      " [2.00000000e+00 0.00000000e+00 1.91519990e+06 1.91543876e+06\n",
      "  1.95871118e+06]\n",
      " ...\n",
      " [2.00000000e+00 0.00000000e+00 4.04851605e+04 6.85904215e+05\n",
      "  0.00000000e+00]\n",
      " [2.00000000e+00 0.00000000e+00 3.13105319e+06 3.13743154e+06\n",
      "  7.17285327e+06]\n",
      " [2.00000000e+00 0.00000000e+00 3.96879148e+07 0.00000000e+00\n",
      "  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# time delay\n",
    "\n",
    "time_delay = lensed_param_detectable['time_delays']\n",
    "snr = lensed_param_detectable['optimal_snr_net']\n",
    "\n",
    "idx1 = abs(snr)>8\n",
    "idx2 = np.sum(idx1, axis=1)\n",
    "\n",
    "combined = np.column_stack([idx2, time_delay])\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "concatenate() got multiple values for argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m reshaped_array_1d \u001b[38;5;241m=\u001b[39m idx2[:, np\u001b[38;5;241m.\u001b[39mnewaxis, np\u001b[38;5;241m.\u001b[39mnewaxis, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Concatenate the arrays along a new axis\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m combined \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreshaped_array_1d\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m t_double_img \u001b[38;5;241m=\u001b[39m [[row[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m sublist \u001b[38;5;28;01mif\u001b[39;00m sublist[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m combined]\n",
      "File \u001b[0;32m<__array_function__ internals>:179\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: concatenate() got multiple values for argument 'axis'"
     ]
    }
   ],
   "source": [
    "combined = ()\n",
    "\n",
    "# Reshape the 1D array to have the same number of dimensions as the 4D array\n",
    "reshaped_array_1d = idx2[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "\n",
    "# Concatenate the arrays along a new axis\n",
    "combined = np.concatenate((reshaped_array_1d[..., np.newaxis]), time_delay, axis=1)\n",
    "\n",
    "t_double_img = [[row[1:5] for row in sublist if sublist[0] == 2] for sublist in combined]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_double_img = [row[\"time\"] for row in zip(data[\"time\"], data[\"image\"]) if idx2 == 2]\n",
    "time_triple_img = np.array(row[\"time\"] for row in data if row[\"image\"] == 3)\n",
    "time_quadruple_img = np.array(row[\"time\"] for row in data if row[\"image\"] == 4)\n",
    "'''\n",
    "this is for 1-d time_delay array:\n",
    "data = {\"time\": time_delay, \"image\": idx2} \n",
    "time_double_image = [t for t, time_delay in zip(data[\"time\"], data[\"image\"]) if idx2 == 2]\n",
    "'''\n",
    "'''\n",
    "my previous failed version:\n",
    "time_delay_double = [];\n",
    "time_delay_triple = [];\n",
    "time_delay_quadruple = [];\n",
    "for i in idx2:\n",
    "    if i == 2:\n",
    "        time_delay_double.append(time_delay[i]) \n",
    "    elif i == 3:\n",
    "        time_delay_triple.append(time_delay[i])\n",
    "    else:\n",
    "        time_delay_quadruple.append(time_delay[i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[       0.           619877.03062256   664157.56077742  1143588.32010244]\n",
      " [       0.          1105522.59720378  4641565.68998829        0.        ]\n",
      " [       0.          1915199.89696738  1915438.75657793  1958711.18462601]\n",
      " ...\n",
      " [       0.            40485.16051307   685904.21529793        0.        ]\n",
      " [       0.          3131053.1898965   3137431.54424434  7172853.26780279]\n",
      " [       0.         39687914.75653023        0.                0.        ]]\n"
     ]
    }
   ],
   "source": [
    "dt_eff = lensed_param_detectable['time_delays']\n",
    "print(dt_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# double-image\n",
    "dt_eff = lensed_params_detectable['time_delays']\n",
    "time_double_img = np.array(row[\"time\"] for row in data if row[\"image\"] == 2)\n",
    "\n",
    "dt12 = abs(dt_eff[:,1]-dt_eff[:,0])/ (24*3600)\n",
    "dt13 = abs(dt_eff[:,2]-dt_eff[:,0])/ (24*3600)\n",
    "dt14 = abs(dt_eff[:,3]-dt_eff[:,0])/ (24*3600)\n",
    "\n",
    "# select only detectable\n",
    "snr_l = lensed_params_detectable['optimal_snr_net']\n",
    "dt12 = dt12[snr_l[:,1]>8]\n",
    "dt13 = dt13[snr_l[:,2]>8]\n",
    "dt14 = dt14[snr_l[:,3]>8]\n",
    "\n",
    "# select only non-nan values\n",
    "dt12 = dt12[~np.isnan(dt12)]\n",
    "dt12 = dt12[~np.isnan(dt12)]\n",
    "dt12 = dt12[~np.isnan(dt12)]\n",
    "\n",
    "log_t12 = np.log10(dt12)\n",
    "log_t13 = np.log10(dt13)\n",
    "log_t14 = np.log10(dt14)\n",
    "# plot time delays\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(log_t12, bins=30, alpha=0.8, label='dt12', density=True, histtype='step')\n",
    "plt.hist(log_t13, bins=30, alpha=0.8, label='dt13', density=True, histtype='step')\n",
    "plt.hist(log_t14, bins=30, alpha=0.8, label='dt14', density=True, histtype='step')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4)\n",
    "plt.xlabel(r'dt [log10(days)]')\n",
    "plt.ylabel(r'$P(dt)$')\n",
    "plt.title('Time delays wrt to first image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pylab import *\n",
    "log(e) # NOT RECOMMENDED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "1 5\n",
      "5\n",
      "[1 2 3 4 5 6]\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "print(a)\n",
    "print(a[0],a[4]) # beware, very different in other languages !\n",
    "print(len(a))   # how long is an array ? \n",
    "\n",
    "b = np.append(a,6) # append element to an array, leaves original array intact\n",
    "print(b)\n",
    "a = np.append(a,[6,7,8,9,10]) # if you want to change the original array\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "mylist = [1,2,3,4]\n",
    "mylist.append(5) # actually changes the list ! Compare to Numpy arrays. Disgusting, huh ? \n",
    "print(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, [6, 7]]\n",
      "[1, 2, 3, [6, 7], 8, 9, 10, 11]\n",
      "[1, 2, 3, [6, 7], 8, 9, 10, 11, '12', 13]\n"
     ]
    }
   ],
   "source": [
    "l = [1,2,3]\n",
    "l.append([6,7]) # should append individual elements 6 and 7, right ?\n",
    "print (l)           # woah, what happened ?\n",
    "\n",
    "l.extend([8,9,10,11])    # this is what we really meant\n",
    "print (l)\n",
    "l.extend(['12', int(13)]) # mixing types is allowed for list\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\n",
      "[ 5 10 15 20 25]\n"
     ]
    }
   ],
   "source": [
    "print(mylist * 5)\n",
    "print(np.array(mylist)*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.    7.    8.  100.  -20.2]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "-1.0\n",
      "-20.2\n",
      "[-1.  7.  8.]\n",
      "[5 6 7 8 9]\n",
      "[ 0  2  4  6  8 10 12 14 16 18]\n",
      "[ 4  7 10 13]\n"
     ]
    }
   ],
   "source": [
    "# Some basics \n",
    "a = np.array([-1, 7, 8, 100, -20.2])\n",
    "b = np.array(range(20))\n",
    "print(a)\n",
    "print(b)\n",
    "print (a[0])      # indexing\n",
    "print (a[-1])\n",
    "print (a[:3])     # slicing\n",
    "print (b[5:10])\n",
    "print (b[::2])   # striding\n",
    "print (b[4:15:3]) # [start:stop:skip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.]\n",
      "[[[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# These will always be full of zeros\n",
    "print (np.zeros(5))\n",
    "print (np.zeros([3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False]\n",
      " [False False]]\n",
      "[[ True  True]\n",
      " [ True  True]]\n"
     ]
    }
   ],
   "source": [
    "print (np.zeros([2,2], dtype='bool'))\n",
    "print (np.ones([2,2], dtype='bool'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "m = np.zeros([3,3], dtype = float)\n",
    "m[0,:]=[1,2,3]\n",
    "m[1,:]=[4,5,6]\n",
    "m[2,:]=[7,8,9]\n",
    "print (m)\n",
    "print (m[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]] \n",
      "\n",
      "[6 6 6] \n",
      "\n",
      "[[5 5 5]\n",
      " [5 5 5]\n",
      " [5 5 5]]\n"
     ]
    }
   ],
   "source": [
    "u = np.array([[1, 1, 1],\n",
    "              [1, 1, 1],\n",
    "              [1, 1, 1]])\n",
    "v = np.array([1,2,3])\n",
    "print (u*v,\"\\n\")            \n",
    "print (np.matmul(u,v),\"\\n\") # this is how numpy does linear algebra !\n",
    "print (u*5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
